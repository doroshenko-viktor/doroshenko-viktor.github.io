<!DOCTYPE html><html><head><meta name="viewport" content="width=device-width"/><meta charSet="utf-8"/><title>Regression In Machine Learning</title><link rel="icon" href="/images/favicon.ico"/><meta name="next-head-count" content="4"/><link rel="preload" href="/_next/static/css/b65b5b41f2379875.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b65b5b41f2379875.css" data-n-g=""/><link rel="preload" href="/_next/static/css/0d9654b911e08999.css" as="style"/><link rel="stylesheet" href="/_next/static/css/0d9654b911e08999.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/_next/static/chunks/webpack-69bfa6990bb9e155.js" defer=""></script><script src="/_next/static/chunks/framework-fc97f3f1282ce3ed.js" defer=""></script><script src="/_next/static/chunks/main-f4ae3437c92c1efc.js" defer=""></script><script src="/_next/static/chunks/pages/_app-85d7488a393e293e.js" defer=""></script><script src="/_next/static/chunks/211-ca3cd870e26e881a.js" defer=""></script><script src="/_next/static/chunks/pages/notes/%5B...noteKey%5D-bc6552c3ae1e3718.js" defer=""></script><script src="/_next/static/rEbIxoA2O-xiW5DUZwlG8/_buildManifest.js" defer=""></script><script src="/_next/static/rEbIxoA2O-xiW5DUZwlG8/_ssgManifest.js" defer=""></script><script src="/_next/static/rEbIxoA2O-xiW5DUZwlG8/_middlewareManifest.js" defer=""></script></head><body><div id="__next"><section class="Layout_centeredSection__nmU9U"><ul class="NavigationBar_navbar__CBMoV"><li class="NavigationBar_navitem__LKB5F"><a class="NavigationBar_navitemContent__jEyWq" href="/">Home</a><span class="NavigationBar_separator__qvEVD">|</span></li><li class="NavigationBar_navitem__LKB5F"><button class="NavigationBar_navitemContent__jEyWq">Back</button><span class="NavigationBar_separator__qvEVD">|</span></li></ul><h1 class="NoteFormattedContent_noteTitle__Oi9sD">Regression In Machine Learning</h1><article class="NoteFormattedContent_note__8cHeE">
<p>Regression models <code>linear</code> and <code>non-linear</code> are used for predicting a real unknown values by set of known similar values.</p>
<h2>Types Of Regression Models</h2>
<ul>
  <li>Simple Linear Regression</li>
</ul>
<p>Ordinary list squares - is a method allowing to find best linear regression approximation between all other possible.</p>
<ul>
  <li>Multiple Linear Regression</li>
  <li>Polynomial Regression</li>
  <li>Support Vector for Regression (SVR)</li>
  <li>Decision Tree Regression</li>
  <li>Random Forest Regression</li>
</ul>
<h2>Assumptions Of Linear Regression</h2>
<p>
  Linear regression fit not every scenario. Before applying it, need to test some assumptions on our data set, which will allow
  to understand if it is suitable.
</p>
<ul>
  <li>There should be approximate linear relation between dependent and independent parameters.</li>
  <li>Homoscedasticity - there should not be a cone shape of dataset distribution</li>
  <li>There should be a normal distribution of our dataset</li>
  <li>
    Independence of dataset. Which means that each value in our dataset does not depend on any characteristic of other values
    in this dataset
  </li>
  <li>Coefficients should not correlate to each other</li>
  <li>Absence of outliers</li>
</ul>
<h2>Categorical Data</h2>
<p>
  To represent categorical data each discreet value of category split into separate coefficient with value 1 if it is a value of
  this category and 0 otherwise.
</p>
<p>
  <strong>Dummy variable trap</strong> - important to note that there should be always n-1 coefficient if there is n discreet values of
  categorical value. Otherwise model will work unreliably.
</p>
<h2>Logistic Regression</h2>
<p>
  Allows to predict categorical values. Usually <code>yes</code> or <code>no</code> and their likelihood. For example predict whether customer with
  given characteristics will buy or not.
</p>
</article></section></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"noteKey":["data science","machine learning","regression"],"note":{"title":"Regression In Machine Learning","date":"2023-08-16","content":"\n\u003cp\u003eRegression models \u003ccode\u003elinear\u003c/code\u003e and \u003ccode\u003enon-linear\u003c/code\u003e are used for predicting a real unknown values by set of known similar values.\u003c/p\u003e\n\u003ch2\u003eTypes Of Regression Models\u003c/h2\u003e\n\u003cul\u003e\n  \u003cli\u003eSimple Linear Regression\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eOrdinary list squares - is a method allowing to find best linear regression approximation between all other possible.\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003eMultiple Linear Regression\u003c/li\u003e\n  \u003cli\u003ePolynomial Regression\u003c/li\u003e\n  \u003cli\u003eSupport Vector for Regression (SVR)\u003c/li\u003e\n  \u003cli\u003eDecision Tree Regression\u003c/li\u003e\n  \u003cli\u003eRandom Forest Regression\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eAssumptions Of Linear Regression\u003c/h2\u003e\n\u003cp\u003e\n  Linear regression fit not every scenario. Before applying it, need to test some assumptions on our data set, which will allow\n  to understand if it is suitable.\n\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003eThere should be approximate linear relation between dependent and independent parameters.\u003c/li\u003e\n  \u003cli\u003eHomoscedasticity - there should not be a cone shape of dataset distribution\u003c/li\u003e\n  \u003cli\u003eThere should be a normal distribution of our dataset\u003c/li\u003e\n  \u003cli\u003e\n    Independence of dataset. Which means that each value in our dataset does not depend on any characteristic of other values\n    in this dataset\n  \u003c/li\u003e\n  \u003cli\u003eCoefficients should not correlate to each other\u003c/li\u003e\n  \u003cli\u003eAbsence of outliers\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eCategorical Data\u003c/h2\u003e\n\u003cp\u003e\n  To represent categorical data each discreet value of category split into separate coefficient with value 1 if it is a value of\n  this category and 0 otherwise.\n\u003c/p\u003e\n\u003cp\u003e\n  \u003cstrong\u003eDummy variable trap\u003c/strong\u003e - important to note that there should be always n-1 coefficient if there is n discreet values of\n  categorical value. Otherwise model will work unreliably.\n\u003c/p\u003e\n\u003ch2\u003eLogistic Regression\u003c/h2\u003e\n\u003cp\u003e\n  Allows to predict categorical values. Usually \u003ccode\u003eyes\u003c/code\u003e or \u003ccode\u003eno\u003c/code\u003e and their likelihood. For example predict whether customer with\n  given characteristics will buy or not.\n\u003c/p\u003e\n"}},"__N_SSG":true},"page":"/notes/[...noteKey]","query":{"noteKey":["data science","machine learning","regression"]},"buildId":"rEbIxoA2O-xiW5DUZwlG8","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>